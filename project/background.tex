\chapter{Background}


\section{The wind farm layout optimization problem}
The goal of this section is to give the reader an understanding of the wind farm layout optimization problem, and explain the key factors that makes the problem so complex.


\subsection{Definition of the wind farm layout optimization problem}
An overview of the wind farm layout optimization problem is presented by Samorani \textcolor{red}{[Samorani, 2013]}. Grouping of wind turbines in a wind farm decreases installation and maintenance cost. However, positioning of wind turbines in a farm also introduces new challenges. The power produced by wind turbines is largely dependent on wind speed, therefore it is important that the wind speed that hits a wind turbine is as large as possible. The main challenge for wind farms is that a wind turbine positioned in front of another wind turbine will cause a wake of turbulence, meaning that the wind speed that hits the second wind turbine will be decreased. This effect is called "wake effect", and will be explained later. Since the goal is to produce as much power as possible it is very important to position the wind turbines so that the wake effect is minimal. Samorani states the wind farm layout optimization problem like this ''The wind farm layout optimization problem consists of finding the turbine positioning (wind farm layout) that maximizes the expected power production". However, in this thesis, the problem formulation will be extended to include cost constraints and also the problem of deciding the number of wind turbines, not just their positions. A formal definition is given below


\begin{quote}
\textit{''The wind farm layout optimization problem consists of finding the number of turbines and turbine positioning (wind farm) that maximizes the expected power production within a given budget.''}
\end{quote}


\subsection{Challenges of wind farm construction}
Samorani gives an overview of the main challenges of wind farm construction. First, a suitable site has to be found, meaning a site with good wind conditions. Sites are classified in 7 different wind power classes, where sites with power class 4 or higher are suitable for hosting a wind farm with today's turbine technology. But, even though the wind farm has the required wind conditions, it might not be suitable for hosting a find farm after all, because it might be far from the electronic grid, so that connecting it to it would be to costly, or it could require costly road work because current roads cannot handle the transportation trucks.\\

\noindent Second, land owner has to be contacted and convinced that hosting a wind farm on their land is a good idea. Land owners usually gets a percentage of the wind farm profit. This phase of contract negotiation  usually takes a few months. At the same time, wind distribution needs to be measured as accurately as possible. This step is extremely important, since the layout of the farm is optimized based on the measured wind distribution. Getting enough data to capture the wind distribution can take a few months if wind conditions are similar all year long, but if the wind conditions vary extensively over the year this step can take a few years. \\

\noindent An evenly important step is to decide on which turbines to buy for the wind farm. Larger turbines usually generate more power, but they are also more expensive than smaller ones. There is therefore a trade off between the cost and power production. Realistic estimation of maintenance cost is also crucial in deciding on turbine type. In \textcolor{red}{[Samorani, 2013]} the number of wind turbines are also decided in this step, but in this project, deciding the number of turbines is included in the wind farm layout optimization problem and will therefore be part of the next step. \\

\noindent After the site is found, turbine type is decided and wind distribution is measured, the layout optimization can begin. Layout optimization faces different challenges, such as positions of the terrain that contain obstacles so that turbines cannot be positioned there. There are also constraint on how close turbines can be positioned, according to \textcolor{red}{[\c{S}i\c{s}bot et al., 2010]}, the minimum spacing rule states that the minimum distance between turbines is 8D in prevailing wind direction, and 2D in cross wind direction, where D is the rotor diameter. However, the greatest challenge of wind farm layout optimization is the wake effect. As mentioned above, the wake effect is the effect of reduced wind speed in the wake behind a wind turbine. Samorani explains the wake effect using the Jensen wake model \textcolor{red}{[Jensen, 1983]}, other wake models exist, but most research in wind farm layout optimization use the Jensen model because it is quite accurate and simple. The Jensen model will also be used briefly in this project, to give an intuitive explanation of the wake effect. 

\begin{figure}[h!]
\begin{center}
\includegraphics[scale=0.5]{images/"Wake Effect"}
\caption{The wake effect \textcolor{red}{[Samorani, 2013]}}
\label{Wake effect}
\end{center}
\end{figure}

In figure \ref{Wake effect} the small black rectangle represents a wind turbine, and the blue area behind it illustrates the area that is affected by the turbulence created by the wind turbine. In the figure, the wind is blowing from left to right with uniform wind speed of $U_0$. As the wind hits the wind turbine it creates a wake of turbulence behind it so that the wind speed at distance $x$ behind the wind turbine is $U < U_0$. The area behind the wind turbine that is affected by the wake at distance $x$ has the radius $r_1 = \alpha x + r_r$ where $r_r$ is the rotor radius and $\alpha$ is the entrainment constant constant which decides how fast the wake expands. For a detailed, mathematical explanation of the Jensen model and other wake models see \textcolor{red}{[Jensen, 1983]}, \textcolor{red}{[Liang et al., 2014]}.\\

\noindent In summary, construction of a wind farm is a complicated, time consuming process. In order to even start the layout optimization consecutive important decisions has to be made. The layout optimization is dependent on turbine cost, terrain parameters, wind conditions and turbine positioning. Finding the optimal layout is a non-linear, complex problem that only sophisticated algorithms can solve.


\section{Genetic Algorithms}


The genetic algorithm (GA) was first introduced by John Henry Holland, even though he did not call it the genetic algorithm at the time. This section gives an overview of the workings and most important operations of the genetic algorithm. If not otherwise stated, everything in this section is based on Holland's book ''Adaptation in natural and artificial systems'' as well as Goldberg's book "Genetic algorithms in search, optimization and machine learning'' \textcolor{red}{[Holland, 1975]} \textcolor{red}{[Goldberg 1989]}.


\subsection{Simple Genetic Algorithms (SGAs)}
Genetic algorithms are probabilistic search algorithms inspired by evolution. By performing selection based on survival of the fittest and genetic operations, genetic algorithms are able to solve problems that are too complex to be modeled mathematically. By utilizing evolution as search strategy, genetic algorithms are able to find sophisticated solutions to problems where the structure of the solution is complex, maybe even unknown. \\

\begin{figure}[h!]
\begin{center}
\includegraphics[scale=0.5]{images/"GA"}
\caption{Overview of the phases of the genetic algorithm. First an initial population is generated and initialized as the first child population. Second, each individual in the child population is evaluated. Third, based on their evaluation, individuals are selected to become parents for the next generation. Forth, a new generation is generated by reproduction, and fifth, the newly generated population becomes the child population.}
\label{GA}
\end{center}
\end{figure}

\noindent Genetic algorithms starts out by randomly generating a set of solutions to a problem, the set of solutions constitutes the population of the first generation of solutions. Next, each individual in the initial population is evaluated based on some predetermined objective function. Based on their objective function values, the fittest individuals are selected for reproduction, meaning that they become the parents of the next generation. By utilizing different genetic operations on the parent solutions a new child population is generated, hopefully with higher average fitness than the previous population since it is based on the fittest individuals from the previous population, and the process repeats itself until the population has found an desirable solution - a population of high-fitness solutions. The different phases of the genetic algorithm is displayed in figure \ref{GA}.\\

\noindent Two key properties are crucial for the genetic algorithm to be useful, (a) there has to be a way to measure the fitness of the individuals, (b) there need to be a way to represent the individuals so that genetic operations can be performed on them. The section below discuss how individuals usually are represented for genetic algorithms.


\subsubsection{Representation}%Search space
In genetics, they call an organisms hereditary information for its genotype, and its observable properties its phenotype. For example, the hereditary information in your genes (genotype) are responsible for your eye color (phenotype).\\

\noindent The genetic search algorithm works on genotypes represented as bit strings. Goldberg explained this with a simple example. Let's say the objective function that we want to find an optimal solution for is $x^2$ for $x \in \{0, 31\}$. Then we can generate genotypes for the random solutions using bit strings of size 5, each representing a phenotype value between 0 and 31. Figure \ref{Representation} displays the genotype and phenotype for four randomly generated individuals for two generations. Here, the phenotypes are just the genotypes on decimal form, but in other problems the phenotype could be everything from eye color to a wind farm.\\


\begin{figure}[h!]
\begin{center}
\includegraphics[scale=0.2]{images/"Representation"}
\caption{Genotypes and phenotypes for four individuals in two generations. On the left side is the randomly generated first generation, and on the right side is the next generation after selection, mutation (red square) and crossover operations. The fitness function used is $x^2$ and as shown the average fitness of the populations increases from 126 to 261 in only one generation.}
\label{Representation}
\end{center}
\end{figure}


\noindent The different colors of each individual in figure \ref{Representation} is just there so that it is easy to understand the genetic operations. The operations will be explained in the section below, for now just accept that some fitness-based selection and genetic operations are performed on the individuals to the left to produce the individuals to the right. As you can see the average phenotype values increases from generation 0 to generation 1, and the average fitness, which is just the average of the squared phenotype values, increases form 126 yo 261 in only one generation. 


\subsubsection{Operations}
The sections above explain that the genetic algorithm uses selection of the fittest and genetic operations, but not exactly how this work. This section will explain different selection strategies and the most common genetic operations -  mutation and crossover.


\paragraph{Selection}
Selection is the process of selecting which individuals from a given population that will be the parents of the next generation. It can be done in a number of ways, and some of the most popular strategies will be presented here. \\


\noindent The simplest form of selection is called \textit{elitist selection}, meaning that the \textit{n} best individuals from the population are selected as parents for the next generation. This strategy is extremely simple, but unfortunately not very good because choosing only the best individuals each generation often leads to fast convergence of an non-optimal solution. It is important to prioritize exploration, at least in the beginning of the search, otherwise, parts of the search space that could have lead to the optimal solution is cut off too soon. To maintain diversity in the group long enough to find high-fitness solutions \textit{controlled elitist selection} is preferred.\\


\noindent A very popular controlled elitist selection strategy is \textit{tournament selection} \textcolor{red}{[Razali et al., 2011]}. In tournament selection, groups of \textit{n} individuals are randomly drawn from the population and the best (fittest) individual from the group is chosen as the tournament winner, and is therefore selected. Figure \ref{Tournament selection} illustrates how tournament selection works. In the example, \textit{n} is equal to 3, therefore the three individuals with fitness 9, 4 and 6 are randomly drawn from the population. The individual with fitness 9 wins the tournament and is chosen for reproduction.\\


\begin{figure}[h!]
\begin{center}
\includegraphics[scale=0.2]{images/"Tournament selection"}
\caption{Tournament selection. A group of three individuals are randomly drawn from the pool of all individuals. The best individual  in the group, the one with fitness 9, is selected for reproduction.\textcolor{red}{[Razali et al., 2011]}}
\label{Tournament selection}
\end{center}
\end{figure}


\noindent By varying the value of \textit{n} you can control how much exploration your algorithm should do. If \textit{n} is equal to the population size, this is elitist selection, if \textit{n} is equal to 1 however the search is completely random. This means that low values of \textit{n} leads to more exploration of the search space, and higher values of \textit{n} leads to faster convergence. These properties makes it desirable to vary the value of \textit{n} during the genetic search so that exploration is prioritized at the beginning of the search, while exploitation is prioritized at the end.\\


\noindent Goldberg presents another popular selection process, \textit{roulette wheel selection}. This form of selection uses a roulette wheel where each individual has a slot with size proportional to its fitness. This way, all individuals has a chance of being picked for selection, but the fittest individuals are more likely to be picked. Figure \ref{Roulette wheel selection} presents the roulette wheel for the individuals in figure \ref{Representation}. The yellow individual has a fitness of 18 and therefore a probability of $\frac{18}{40} = 0.45$ of being picked, the blue has the probability of $\frac{11}{40} = 0.275$, the purple $\frac{6}{40} = 0.15$ and the red $\frac{5}{40} = 0.125$. Based on these probabilities the yellow individual was picked twice for selection, the blue and purple one time each, while the red one was not picked at all, and therefore not represented in the next generation. This lead to a new generation of individuals with much higher fitness than the previous one, because of inherited properties from good parent solutions. \textcolor{red}{The colors don't make sense in black and white, need to give numbers to each individual in figure \ref{Representation} and  use them in the explanation, not colors.}

\begin{figure}[h!]
\begin{center}
\includegraphics[scale=0.2]{images/"Tournament selection"}
\caption{Roulette wheel selection. [Goldberg, 1989].}
\label{Roulette wheel selection}
\end{center}
\end{figure}


\paragraph{Mutation}
In biology, mutation is defined as a permanent alteration in the DNA sequence that makes up a gene. Mutations vary in size, sometimes just a small base pair of the gene is altered, while other times the mutation can alter large parts of a chromosome. There are many different forms of mutations. Sometimes it can simply mean changing the value of a nucleotide to its complement (nucleotieds are the building blocks of DNA and consists of the values A, C, G and T), other times it can mean insertion of extra nucleotides into the DNA, deleting some of the nucleotides from the DNA, or invertion of nucleotides \textcolor{red}{[Compeau et al., 2014]}. \\


\noindent In genetic computation the mutation process is simplified. Since the search space only consist of strings of bits with constant size, a mutation in genetic computing simply consists of flipping of bits, this is called single point mutation. In Figure \ref{Mutation} we have a bit string of size 8, where the 6th element is mutated from the value 1 to the value 0. Mutation is usually implemented by having a given probability of each value in the genotype being flipped.


\begin{figure}[h!]
\begin{center}
\includegraphics[scale=0.2]{images/"Mutation"}
\caption{Mutation of a single bit. The bit in position 6 at the upper bit string has the value 1 before the mutation, while after mutation the value if flipped into 0.}
\label{Mutation}
\end{center}
\end{figure}


Mutation is important because without mutation a population can converge to a population of individuals where each genotype has the same value at a given position. Since every individual has the same value in their genotype, reproduction will never be able to make a new individual that doesn't also have the same value at the same position. With mutation however, there is always a probability of the value being flipped, mutation is therefore crucial for maintaining diversity in the population.\\


\noindent Even though mutation is important, the probability of mutation needs to be kept low. If the mutation rate is very high, the genotype of a new individual will almost be a random bit string. Remember that a new individual is made by reproduction between two individuals with high fitness in the previous population, if mutation heavily changes the new individual, it will not inherit the good features of its parents and the whole point of evolutionary search will be gone.


\paragraph{Crossover}
As in nature, we want individuals of the evolutionary search to inherit features from individuals in the previous population. In genetic algorithms this is performed by applying the crossover operation. Crossover is a simple method where a new individual gets some parts of its genotype from one parent, and the other parts from its other parent. Figure \ref{Single point crossover} illustrates the crossover operation. Before crossover is performed one needs to decide at which position it will be performed. If we are operating with genotypes of length 8 as in figure \ref{Single point crossover} there will be 7 possible crossover positions, one between each of the 8 values of the genotype. In figure \ref{Single point crossover} position 4 is picked as the crossover position, therefore the first of the newly produced individuals will have a genotype consisting of the first 4 values of the first individual of the old population and the 4 last values of the second individual of the old population, while the second newly generated individual will get the opposite genotype.


\begin{figure}[h!]
\begin{center}
\includegraphics[scale=0.2]{images/"Single point crossover"}
\caption{Single point crossover at position 4.}
\label{Single point crossover}
\end{center}
\end{figure}


\noindent The crossover in figure \ref{Single point crossover} is called a single point crossover, because crossover is only performed at one position. It is also possible to have multiple crossover positions as shown in figure \ref{Double point crossover}, where a double point crossover is performed with crossover positions 2 and 5.


\begin{figure}[h!]
\begin{center}
\includegraphics[scale=0.2]{images/"Double point crossover"}
\caption{Double point crossover at position 2 and 5.}
\label{Double point crossover}
\end{center}
\end{figure}


\noindent Crossover probability is usually kept high because one is hoping that combining to good solutions from the previous population will produce even better solutions for the next population. However, it is desirable to keep some solutions from the previous population as they are, because they might be better then combination of two of them. \\


\noindent Goldberg performs a very interesting analysis of the crossover operation by studying the probability of surviving a crossover operation for different schemata. A schema is a string taken from the library \{0, 1, *\}.  A shema of size 8 could therefore for example look like this \textit{0011****}, where \textit{0} and \textit{1} represents letters with values 0 and 1, while \textit{*} represents letters that we don't care about. This means that both strings \textit{00110000} and \textit{00111111} are covered by the given schema. If desirable features are represented by schemata it is easy to see that some features are much more likely to survive a single point crossover operation than others. Lets study the shemata $s_1 = 11******$ and $s_2  = 1******1$. Both has size 8, meaning that there are 7 possible crossover positions. However, only one of the crossover positions will destroy $s_1$ while all 7 positions will break up $s_2$. This means that the genetic search would converge faster if $s_1$ was the desirable feature, then if $s_2$ was.


\subsection{Distributed Genetic Algorithms (DGAs)}
On of the main challenges of simple genetic algorithms is keeping diversity in the population long enough so that the population do not converge to a sub-optimal solution. By distributing the population, the population is able to explore different solution paths, even some that does not look that good at first, and consequently get the opportunity to find better, more sophisticated solutions. \\

\noindent The goal of this thesis is to investigate and compare the performance of different distributed genetic algorithms in solving the wind farm layout optimization problem. In order to give an answer to the research questions, different distributed genetic algorithms needs to be implemented and tested. This section introduces five different population-distributed algorithms presented by \textcolor{red}{[Gong et al., 2015]}. These will all be implemented and tested in this thesis.\\


\subsubsection{The Master-Slave Model}

The master-slave model is not really a distributed genetic algorithm, but a simple genetic algorithm where the main operations of the algorithm are distributed between different processors. It will be implemented in this thesis for two reasons; (1) distributing tasks between different processors gives a faster-running algorithm than an simple genetic algorithm, (2) results obtained will be the same as results obtained by a simple genetic algorithm, and can therefore be used to compare against true distributed algorithms. The master-slave model is displayed in figure \ref{Master-Slave Model}.\\


\begin{figure}[h!]
\begin{center}
\includegraphics[scale=0.3]{images/"Master-Slave Model"}
\caption{Master-slave model. The master process distributes the population to different slave processes, which calculate the fitness of each individual and return the results to the master process \textcolor{red}{[Gong et al, 2014]}.}
\label{Master-Slave Model}
\end{center}
\end{figure}


\noindent When the master-slave model is used, the main loop is taken care of by the master process, however the most expensive operation in the genetic algorithm, calculation of fitness, is distributed to different slave processes. Each slave simply calculate the fitness of the individuals received from the master, and return the calculated fitness to the master. 


\subsubsection{The Island Model}
In the island model, the population is divided into sub populations that are distributed onto different islands. By letting each population evolve separately different islands can explore different solutions. Figure \ref{Island model} displays a population divided into four sub populations. \\ 


\begin{figure}[h!]
\begin{center}
\includegraphics[scale=0.3]{images/"Island Model"}
\caption{An island model using a ring topology with four demes of size five. \textcolor{red}{[Gong et al., 2014]}}
\label{Island model}
\end{center}
\end{figure}


According to \textcolor{red}{[Huang, 2007]}, six parameters needs to be specified when using the island model. First of all, the deme size needs to be specified; the number of individuals on each island (deme). Second, one needs to decide on the number of demes. In figure \ref{Island model} the deme size is five and four demes are used. Third, the topology must be specified; the allowed routes to migrate from one population to another. Numerous topologies can be used. In figure \ref{Island model} the arrows are the legal migration routes, since the topology forms a circle it is called a ring topology. The forth and fifth parameters listed by Huang are migration rate and migration interval, meaning the number of individuals that migrate from one population to another and the number of generations between each migration respectively. These parameters are very important since they largely affect the time the population gets to explore different solutions before the best solutions from some of the demes takes over the population. Sixth, the policy of selection emigrants and how to replace existing individuals with new migrants. \\


\noindent The above parameters must be given careful thought when implementing the island model, but as Gong explains, they are not the only ones. If the island model is implement in parallel one also have to decide if the migration is synchronous or asynchronous. Synchronous migration means that all migration is performed at the same time; at a specific generation, while as asynchronous migration is used migration can be performed whenever one of the parallel processes is ready. Additionally, it has to be decided if the island model is homogeneous or heterogeneous. By a homogeneous island model, Gong means an island model where each sub population use the same selection strategy, genetic operations and fitness function, while as an heterogeneous island model can implement different settings for different sub populations.


\subsubsection{The Cellular Model}
Figure \ref{Cellular model} displays the cellular model from \textcolor{red}{[Gong, 2014]}. In the cellular model the population is distributed in a grid of cells where each cell holds one individual. Each individual only ''sees'' the individuals of its neighborhood (as decided by the given neighborhood topology) and can only be compared with and mate with individuals in its neighborhood. \\


\begin{figure}[h!]
\begin{center}
\includegraphics[scale=0.3]{images/"Cellular Model"}
\caption{Cellular model where the neighborhood topology consist of the cells to the left, right, over and under the given cell. \textcolor{red}{[Gong et al, 2014]}}
\label{Cellular model}
\end{center}
\end{figure}


\noindent The takeover time is defined as the time it takes for one individual to propagate to the whole population. The neighborhood topology largely affects the takeover time. In figure \ref{Cellular model} the neighborhood topology is defined as only the individuals left, right, over and under the given individual. Since the topology includes a small number of individuals the takeover time will be very long, meaning that exploration is prioritized. If the topology consist of a larger number of cells the takeover time will, off course, be mush shorter.\\


\noindent The cellular model can also be implemented in parallel, ideally with one processor for each cell. As in the island model, updating of the cells can be both synchronous and asynchronous. Synchronous updating means that all the cells are updated at the same time, while as asynchronous updating means that each cell is updated at a certain time following some updating scheme. 


\subsubsection{Hybrid Models}
Hybrid models, are distributed genetic algorithms that combine different distributed genetic algorithm models. Gong et al. presented the three different hybrid models presented in figure \ref{Hybrid Models}.\\


\begin{figure}[h!]
    \centering
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth, height=4cm]{images/"Island-Master-Slave Hybrid"}
        \caption{}
    \end{subfigure}
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth, height=4cm]{images/"Island-Cellular Hybrid Model"}
        \caption{}
    \end{subfigure}
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth, height=4cm]{images/"Island-Island Hybrid Model"}
        \caption{}
    \end{subfigure}
    \caption{Different hybrid models. (a) Island-master-slave hybrid model, (b) Island-cellular hybrid model, and (c) Island-island hybrid model \textcolor{red}{[Gong et al., 2014]}.}
    \label{Hybrid Models}
\end{figure}


\noindent The first hybrid model combines the island model with the master-slave model. By combining these two models, each deme will be processed faster because it is distributed between different processors. The second model combines the island model and the cellular model. By combining these two models the diversity within a given deme can be kept longer than when the simple island model is used, and make sure premature convergence will not happen in the demes. The last model has a similar function as the second one, but instead of using the cellular model in each deme, it uses the island model inside the demes. \\


\subsubsection{Pool Model}
Another distributed model is called the pool model. In this model the population is put in a shared global pool of $n$ individuals, where it can be accessed by different processors. Each processor draws a population from random positions of the pool, however it has allocated its own positions for which it can return individuals to the pool. This process is demonstrated in figure \ref{Pool Model}. \\


\begin{figure}[h!]
\begin{center}
\includegraphics[scale=0.3]{images/"Pool Model"}
\caption{The pool model. Each processor has its own positions in the pool for which it is responsible to return individuals to. The red processor is responsible for the red positions in the pool, and so on. Processors draw individuals from random positions in the pool, but writes them back to its own positions, given that their fitness are higher than the individuals currently occupying the position \textcolor{red}{[Gong et al., 2014]}.}
\label{Pool Model}
\end{center}
\end{figure}


\noindent A processor $p_1$ has $k$ positions in the pool for which it is responsible for as can be seen in figure \ref{Pool Model}, where the processor and the positions it is responsible for has the same color. It draws a population of individuals $i_1, i_2,...,i_k$ from random positions in the pool, performs genetic operations and fitness calculations, and write each individual back to its corresponding position $1, 2,...,k$ in the the positions it is responsible for, given that their fitness is higher then the fitness of the individual currently occupying the position. Key design decisions in this model is individual selection policy and replacement policy.\\
